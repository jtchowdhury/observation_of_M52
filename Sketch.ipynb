{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bea2278-4367-4b68-9cc9-f8d54a26bc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakia\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bfc62e-ed7e-4a74-8ea5-8f6cb7a04d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Amherst\\ASTR-337\n"
     ]
    }
   ],
   "source": [
    "cd ..\\..\\Amherst\\ASTR-337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd3a30b-91bf-4fa1-812b-5f311955ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.visualization import ZScaleInterval\n",
    "%matplotlib inline\n",
    "from astropy.io import fits\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "from scipy.ndimage import shift"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4aae3fc-d1a4-447c-838e-551e3b2ccfa5",
   "metadata": {},
   "source": [
    "Master bias generation function from Lab 5/Homework 6\n",
    "Inputs: \n",
    "a list of all bias file paths\n",
    "a path to save the master bias\n",
    "Returns: master bias in array form\n",
    "should also save the master bias in *.fits format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0d602a-acb6-44ef-a634-5876e6679a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_bias(filelist, outputfile):\n",
    "    '''\n",
    "    Generates a master bias from a list of bias frames, writes the master file in .fit format\n",
    "    \n",
    "    Parameters: \n",
    "    filelist (list of str): A list containing all the bias files\n",
    "    outputfile (str): a file path to save master bias file\n",
    "    \n",
    "    Returns:\n",
    "    Array of master bias \n",
    "    '''\n",
    "    # set n equal to the number of files in filelist\n",
    "    n = len(filelist)\n",
    "\n",
    "    # get first frame header\n",
    "    first_frame_header = fits.getheader(filelist[0])\n",
    "\n",
    "    # set first_frame_data equal to the data array of the first file in filelist\n",
    "    first_frame_data = fits.getdata(filelist[0])\n",
    "\n",
    "    # get the dimensions of the first file in filelist\n",
    "    imsize_y, imsize_x = first_frame_data.shape\n",
    "\n",
    "    # set the values in the array equal to zero\n",
    "    fits_stack = np.zeros((imsize_y, imsize_x , n))\n",
    "\n",
    "    # Insert each frame into a three dimensional stack, one by one:\n",
    "    for ii in range(0, n):\n",
    "        im = fits.getdata(filelist[ii])\n",
    "        fits_stack[:,:,ii] = im\n",
    "\n",
    "    # Take the median of the stack\n",
    "    med_frame = np.median(fits_stack, axis = 2)\n",
    "\n",
    "    # create output file directory if it does not exist\n",
    "    if not os.path.exists(os.path.dirname(outputfile)):\n",
    "        os.mkdir(os.path.dirname(outputfile))\n",
    "    \n",
    "    # write median combined output fits file\n",
    "    fits.writeto(outputfile, med_frame, header=first_frame_header, output_verify='exception', overwrite=True, checksum=False)\n",
    "    print(f\"Master Bias file saved as: {os.path.basename(outputfile)}\")\n",
    "\n",
    "    return med_frame"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5337a64f-bd0b-450f-ad93-63acffc6df78",
   "metadata": {},
   "source": [
    "Master dark generation function from Lab 5/Homework 6\n",
    "Inputs: \n",
    "a list of all dark file paths\n",
    "the master bias (either the path to the master bias or the mbias array itself)\n",
    "a path to save the master dark\n",
    "\n",
    "Returns: master dark in array form\n",
    "should also save the master dark in *.fits format!\n",
    "Note: This will need to be modified slightly to normalize the dark images by exposure time! See slide 20 in Week 7 slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7cc5e9-ebea-44bd-86d4-ad6302e08bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_dark(filelist, master_bias, outputfile):\n",
    "    '''\n",
    "    Generates a master dark from a list of dark frames, writes the master file in .fit format\n",
    "\n",
    "    Parameters:\n",
    "    filelist (str): list of all dark frame fits files\n",
    "    master_bias (array): the array of master bias\n",
    "    outputfile (str): a file path to save master dark file \n",
    "\n",
    "    Returns:\n",
    "    array: master dark frame\n",
    "    '''\n",
    "    # set n equal to the number of files in filelist\n",
    "    n = len(filelist)\n",
    "\n",
    "    # get first frame header\n",
    "    first_frame_header = fits.getheader(filelist[0])\n",
    "\n",
    "    # set first_frame_data equal to the data array of the first file in filelist\n",
    "    first_frame_data = fits.getdata(filelist[0])\n",
    "\n",
    "    # get the dimensions of the first file in filelist\n",
    "    imsize_y, imsize_x = first_frame_data.shape\n",
    "\n",
    "    # set the values in the array equal to zero\n",
    "    fits_stack = np.zeros((imsize_y, imsize_x , n))\n",
    "\n",
    "    # Insert each frame into a three dimensional stack, subtracts bias\n",
    "    # and normalizes by exposure time, one by one:\n",
    "    for ii in range(0, n):\n",
    "        exptime = fits.getheader(filelist[ii])['EXPTIME']\n",
    "        im = (fits.getdata(filelist[ii]) - master_bias) / exptime\n",
    "        fits_stack[:,:,ii] = im\n",
    "\n",
    "    # Take the median of the stack\n",
    "    med_frame = np.median(fits_stack, axis = 2)\n",
    "\n",
    "    # create output file directory if it does not exist\n",
    "    if not os.path.exists(os.path.dirname(outputfile)):\n",
    "        os.mkdir(os.path.dirname(outputfile))\n",
    "    \n",
    "    # write median combined output fits file\n",
    "    fits.writeto(outputfile, med_frame, header=first_frame_header, output_verify='exception', overwrite=True, checksum=False)\n",
    "    print(f\"Master dark file saved as: {os.path.basename(outputfile)}\")\n",
    "\n",
    "    return med_frame"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90beafe4-d282-4d55-8d03-63539f112a93",
   "metadata": {},
   "source": [
    "Flat field generation function from Lab 5/Homework 6\n",
    "Inputs: \n",
    "a list of all flat files to combine\n",
    "the master bias (either the path to the master bias or the mbias array itself)\n",
    "the master dark (either the path to the master dark or the mdark array itself)\n",
    "a path to save the master flat\n",
    "Returns: none\n",
    "should save the master flat in *.fits format!\n",
    "Note: This will need to be modified slightly - see slide 20 in Week 7 slides. Note that there are two equations that must both be applied in order to create the master flat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d48c62e-127d-4a6d-8c9e-213d1a609f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_flat(filelist, master_bias, master_dark, outputfile):\n",
    "    '''\n",
    "    Generates a master flat from a list of flat frames, writes the master file in .fit format\n",
    "\n",
    "    Parameters:\n",
    "    filelist (str): list of all dark frame fits files\n",
    "    master_bias (array): the array of master bias\n",
    "    master_dark (array): the array of master dark\n",
    "    outputfile (str): a file path to save master flat file \n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    '''\n",
    "    # number of files in the list\n",
    "    n = len(filelist)\n",
    "\n",
    "    # get first frame header\n",
    "    first_frame_header = fits.getheader(filelist[0])\n",
    "\n",
    "    # gets the first file from the list\n",
    "    first_frame_data = fits.getdata(filelist[0])\n",
    "    #print(\"raw: \\n\", first_frame_data)\n",
    "\n",
    "    # saves the dimensions of the fits file\n",
    "    imsize_y, imsize_x = first_frame_data.shape\n",
    "\n",
    "    # Initializes a 3d array\n",
    "    fits_stack = np.zeros((imsize_y, imsize_x , n))\n",
    "\n",
    "    # subtracts bias,normalizes by exposure time, subtracts dark, normalizes by the pixel values, \n",
    "    #then Insert each frame into a three dimensional stack, one by one:\n",
    "    \n",
    "    for ii in range(0, n):\n",
    "        exptime = fits.getheader(filelist[ii])['EXPTIME']\n",
    "        im = ((fits.getdata(filelist[ii]) - master_bias) / exptime) - master_dark\n",
    "        #print(\"subtracted: \\n\",im)\n",
    "        norm_im = im/np.median(im)\n",
    "        #print(\"normalize: \\n\", norm_im)\n",
    "        fits_stack[:,:,ii] = norm_im\n",
    "        \n",
    "    #print(\"stack:\\n\", fits_stack)\n",
    "    \n",
    "    # Gets the median value of the pixels across the 3rd dimension of the array\n",
    "    med_frame = np.median(fits_stack, axis=2)\n",
    "\n",
    "    # create output file directory if it does not exist\n",
    "    if not os.path.exists(os.path.dirname(outputfile)):\n",
    "        os.mkdir(os.path.dirname(outputfile))\n",
    "    \n",
    "    # write median combined output fits file\n",
    "    fits.writeto(outputfile, med_frame, header=first_frame_header, output_verify='exception', overwrite=True, checksum=False)\n",
    "    print(f\"Master flat file saved as: {os.path.basename(outputfile)}\")\n",
    "    #print(med_frame)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4e47480-0781-436a-af67-40d048c46388",
   "metadata": {},
   "source": [
    "Function to bias subtract, dark subtract, and flat field a raw data frame, also from Homework 6 \n",
    "Inputs: \n",
    "path to image\n",
    "the master bias (either the path to the master bias or the mbias array itself)\n",
    "the master dark (either the path to the master dark or the mdark array itself)\n",
    "the path to the “flats” folder\n",
    "a path to save the reduced image\n",
    "Outputs: none\n",
    "should save the reduced data in *.fits format (should be the same path as the input image, but with the prefix ‘fdb_’ added to the front of the filename)!\n",
    "Note: This will need to be modified slightly - see slide 21 in Week 7 slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "757cff04-16a4-4a70-a9c1-b402247088db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_image(img, master_bias, master_dark, flats_path, outputfile):\n",
    "    '''\n",
    "    Reduces the image and writes a new file with the reduced image.\n",
    "    \n",
    "    Parameters:\n",
    "    img (str): path to the image to be reduced\n",
    "    master_bias (array): the array of master bias\n",
    "    master_dark (array): the array of master dark\n",
    "    flats_path (str): the path to the master flat file\n",
    "    outputfile (str): a file path to save the reduced image \n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    '''\n",
    "    # frame header\n",
    "    header = fits.getheader(img)\n",
    "    \n",
    "    # array for image\n",
    "    data = fits.getdata(img)\n",
    "\n",
    "    #Filter from the header\n",
    "    #filter = header['FILTER']\n",
    "    \n",
    "    #Getting the master flat of same filter\n",
    "    #master_flat = fits.getdata(glob.glob(os.path.join(flats_path,filter,'/Master*.fit')[0])\n",
    "    master_flat = fits.getdata(flats_path)\n",
    "\n",
    "    # Reducing image\n",
    "    reduced_img = (data - master_bias - header['EXPTIME']*master_dark) / master_flat\n",
    "\n",
    "    # create output file directory if it does not exist\n",
    "    if not os.path.exists(os.path.dirname(outputfile)):\n",
    "        os.mkdir(os.path.dirname(outputfile))\n",
    "    \n",
    "    # write median combined output fits file\n",
    "    output_filename = os.path.join(outputfile, 'fdb_' + os.path.basename(img))\n",
    "    fits.writeto(output_filename, reduced_img, header=header, output_verify='exception', overwrite=True, checksum=False)\n",
    "    print(f\"Reduced image saved as: {os.path.basename(output_filename)}\")\n",
    "    #print(reduced_img)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d20aad46-0e8a-471b-a40c-325551f516c2",
   "metadata": {},
   "source": [
    "Offset calculation function \n",
    "(You can either use your function from Homework 7, or you can use the cross-correlation function from Lab 6.)\n",
    "Inputs:\n",
    "path to image \n",
    "path to reference image\n",
    "pixel coordinates of star to use for centroiding\n",
    "pixel coordinates centered on an “empty” background patch of sky\n",
    "Outputs: list of x- and y-shifts for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22becb5e-000a-46b2-b8f1-6caf988e2f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_offset(img, ref_img, fg, bg):\n",
    "    \n",
    "    '''\n",
    "    Measure misalignment shift between a reference image and test image.\n",
    "\n",
    "    Arguments:\n",
    "        img (str): path to reference fits files\n",
    "        ref_img (str): path to test fits file to align with referene\n",
    "        bg (tuple): (x, y) center of background region\n",
    "        fg (tuple): (x, y) center of foreground region\n",
    "\n",
    "    Return:\n",
    "        misalignment (tuple): (dy, dx) translation shift from reference to test image\n",
    "\n",
    "    The background region should contain no stars, and the foreground\n",
    "    region should only contain a single star.\n",
    "    '''\n",
    "    \n",
    "    # load reference and test images from fits files\n",
    "    img0 = fits.getdata(img)\n",
    "    img1 = fits.getdata(ref_img)\n",
    "\n",
    "    half_width = 25\n",
    "\n",
    "    # slice background region from reference and test images\n",
    "    bg0 = img0[bg[1] - half_width : bg[1] + half_width, bg[0] - half_width : bg[0] + half_width]\n",
    "    bg1 = img1[bg[1] - half_width : bg[1] + half_width, bg[0] - half_width : bg[0] + half_width]\n",
    "\n",
    "    # slice foreground region from reference and test images\n",
    "    fg0 = img0[fg[1] - half_width : fg[1] + half_width, fg[0] - half_width : fg[0] + half_width]\n",
    "    fg1 = img1[fg[1] - half_width : fg[1] + half_width, fg[0] - half_width : fg[0] + half_width]\n",
    "\n",
    "    # determine significant pixel thresholds based on background regions\n",
    "    thresh0 = np.median(bg0) + 3 * np.std(bg0)\n",
    "    thresh1 = np.median(bg1) + 3 * np.std(bg1)\n",
    "\n",
    "    # determine indices or pixels over threshold in foreground regions\n",
    "    (y0, x0) = np.nonzero(fg0 > thresh0)\n",
    "    (y1, x1) = np.nonzero(fg1 > thresh1)\n",
    "\n",
    "    # determine values of pixels over threshold in foreground regions\n",
    "    thres_arr0 = fg0[y0,x0]\n",
    "    thres_arr1 = fg1[y1,x1]\n",
    "\n",
    "    #Formula:\n",
    "    #x_center = sum(x(R[x,y]-B)) / sum(R[x,y]-B)\n",
    "    #y_center = sum(y(R[x,y]-B)) / sum(R[x,y]-B)\n",
    "\n",
    "    # computed weighted centroids of pixels over threshold in ref img\n",
    "    x_0 = np.sum(x0*(thres_arr0-np.median(bg0))) / np.sum(thres_arr0-np.median(bg0))\n",
    "    y_0 = np.sum(y0*(thres_arr0-np.median(bg0))) / np.sum(thres_arr0-np.median(bg0))\n",
    "    \n",
    "    # computed weighted centroids of pixels over threshold in image to be aligned\n",
    "    x_1 = np.sum(x1*(thres_arr1-np.median(bg1))) / np.sum(thres_arr1-np.median(bg1))\n",
    "    y_1 = np.sum(y1*(thres_arr1-np.median(bg1))) / np.sum(thres_arr1-np.median(bg1))\n",
    "\n",
    "    return (x_0 - x_1), (y_0 - y_1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "069bf0d2-efe4-4f9d-acdf-7c07065b5e45",
   "metadata": {},
   "source": [
    "Image registration function from Homework 8\n",
    "(You should just be able to copy/paste your function without modification.)\n",
    "Inputs:\n",
    "list of files to stack\n",
    "list of offsets to apply to each file\n",
    "padding size\n",
    "a path to save the stacked image\n",
    "Outputs: final image\n",
    "should also save the stacked image in *.fits format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c98b5a-2c22-426e-8769-92ea9d46c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_registraion(files, offsets, padding, outputfile):\n",
    "    '''\n",
    "    Pads, shifts, stacks, and median combines a list of same band images\n",
    "    for a single object.\n",
    "\n",
    "    Arguments:\n",
    "        files (list of strings): list of fit files to process\n",
    "        offsets (list of tuples): list of image misalignments (dx, dy)\n",
    "        padding (int): number of pixels to pad before shifting\n",
    "        outputfile (str): a file path to save the registered image\n",
    "\n",
    "    Return:\n",
    "        final image\n",
    "\n",
    "    The individual padded and shifted images are saved to fit files with\n",
    "    the prefix 's' added to the original fit file name.\n",
    "\n",
    "    The median combined image is saved to a fit file with the prefix\n",
    "    'median_s' added to the first fit file name in the list. \n",
    "    '''\n",
    "    #initializing array of stacked images\n",
    "    img = fits.getdata(files[0])\n",
    "    filter = fits.getheader(files[0])['FILTER']\n",
    "    (x, y) = img.shape\n",
    "    n = len(files)\n",
    "    stack = np.zeros((y + 2 * (padding), x + 2 * (padding), n))\n",
    "    \n",
    "    for ii in range(n):\n",
    "        file = files[ii]\n",
    "        offset = offsets[ii]\n",
    "        img = fits.getdata(file)\n",
    "        hdr = fits.getheader(file)\n",
    "        img[np.isnan(img)] = 0.0\n",
    "        img[np.isinf(img)] = 0.0\n",
    "        padded_img = np.pad(img, padding, 'constant', constant_values = -1)\n",
    "        \n",
    "        shifted_img = shift(padded_img, offset, cval = -1)\n",
    "        shifted_img[np.isnan(shifted_img)] = 0.0\n",
    "        shifted_img[np.isinf(shifted_img)] = 0.0\n",
    "      \n",
    "        # Insert each frame into a three dimensional stack, one by one:\n",
    "        stack[:,:,ii] = shifted_img\n",
    "    \n",
    "        # write padded and shifted fits file\n",
    "        outputfile_name = os.path.join(outputfile, 's_' + os.path.basename(file))\n",
    "        #print('writing shifted image', os.path.basename(outputfile))\n",
    "        fits.writeto(outputfile_name, shifted_img, header=hdr, output_verify='exception', overwrite=True, checksum=False)\n",
    "        print(f\"Shifted image saved as: {os.path.basename(outputfile_name)}\")\n",
    "        \n",
    "    # Take the median of the stack\n",
    "    med_img = np.median(stack, axis = 2)\n",
    "    med_img[np.isnan(med_img)] = 0.0\n",
    "    med_img[np.isinf(med_img)] = 0.0\n",
    "    \n",
    "    # write median combined output fits file\n",
    "    output_filename = os.path.join(outputfile , 'Stacked_image.fit')\n",
    "    fits.writeto(output_filename, med_img, header=hdr, output_verify='exception', overwrite=True, checksum=False)\n",
    "    print(f\"Stacked image saved as: {os.path.basename(output_filename)}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70efac4e-192b-43bc-b033-57df65d39e5b",
   "metadata": {},
   "source": [
    "Make all master calibration files (including flats for each filter).\n",
    "\n",
    "Bias-subtract, dark-subtract, and flat field all images.\n",
    "\n",
    "Compute offsets and register the images:\n",
    "\n",
    "a. In each filter, select a reference image (ideally, one with good S/N)\n",
    "\n",
    "b. Align all images in that filter against this reference image\n",
    "\n",
    "c. Stack images to create a single master image\n",
    "\n",
    "d. Repeat steps a-c for the other filters\n",
    "\n",
    "e. Align all master images to each other\n",
    "\n",
    "Make sure to save all reduced and stacked images as *.fits files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756a544-bfdc-4135-8515-af67a0e67d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't use\n",
    "def reduction(folder_path, object_name):\n",
    "    '''\n",
    "    Performs data reduction on images.\n",
    "\n",
    "    Arguments:\n",
    "        folder_path (string): path to the top level data folder\n",
    "        object_name (string): name of object specific data subfolder\n",
    "\n",
    "    Return:\n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    # Create master bias file\n",
    "    biasfiles = glob.glob(os.path.join(folder_path, 'Calibration', 'Bias', 'CSJ*.fit'))\n",
    "    master_bias_path = os.path.join(folder_path, 'Calibration', 'Bias', 'Master_bias.fit')\n",
    "    m_bias = master_bias(biasfiles, master_bias_path)\n",
    "    \n",
    "    # Create master dark file\n",
    "    darkfiles = glob.glob(os.path.join(folder_path, 'Calibration', 'Dark','CSJ*.fit'))\n",
    "    master_dark_path = os.path.join(folder_path, 'Calibration', 'Dark', 'Master_dark.fit')\n",
    "    m_dark = master_dark(darkfiles, m_bias, master_dark_path) \n",
    "        \n",
    "   # Create master flat file\n",
    "\n",
    "    for filter in ['Red', 'Blue', 'Visual']:\n",
    "        flatfiles = glob.glob(os.path.join(folder_path, 'Calibration', 'Flat', filter ,'PBH*.fit'))\n",
    "        master_flat_path = os.path.join(folder_path, 'Calibration', 'Flat', filter , 'Master_flat.fit')\n",
    "        master_flat(flatfiles, m_bias, m_dark, master_flat_path) \n",
    "\n",
    "    # Reduce object files\n",
    "    for filter in ['Red', 'Blue', 'Visual']:\n",
    "        master_flatfile = os.path.join(folder_path, 'Calibration', 'Flat', filter , 'Master_flat.fit')\n",
    "        objfiles = glob.glob(os.path.join(folder_path, object_name, filter ,'CSJ*.fit'))\n",
    "\n",
    "        for objfile in objfiles:\n",
    "            outputfile = os.path.join(folder_path, object_name, filter)\n",
    "            reduce_image(objfile, m_bias, m_dark, master_flatfile, outputfile)\n",
    "\n",
    "    # Coordinates for Visual, Blue, and Red\n",
    "    fg_V = (1898, 2474) #placeholder\n",
    "    bg_V = (2010, 1860) #placeholder\n",
    "    fg_B = (2725, 1864)\n",
    "    bg_B = bg_V\n",
    "    fg_R = (2890, 1790)\n",
    "    bg_R = (2143, 1944)\n",
    "    \n",
    "    # Compute offsets between object images, and shift, pad, and stack them\n",
    "    for filter in ['Red', 'Blue', 'Visual']:\n",
    "        if filter in 'Visual':\n",
    "            fg = fg_V\n",
    "            bg = bg_V\n",
    "        elif filter in 'Blue':\n",
    "            fg = fg_B\n",
    "            bg = bg_B\n",
    "        else:\n",
    "            fg = fg_R\n",
    "            bg = bg_R\n",
    "        nref = 0 # Simple placeholder - Ideally choose img with best signal to noise ratio\n",
    "        objfiles = glob.glob(os.path.join(folder_path, object_name, filter ,'fdb_*.fit'))\n",
    "        offsets = []\n",
    "        padding = 0\n",
    "        for objfile in objfiles:\n",
    "            (dx, dy) = measure_offset(objfile, objfiles[nref], fg, bg)\n",
    "            offsets.append((dx, dy))\n",
    "            print(f'{objfile} offset by ({dx}, {dy})')\n",
    "            padding = int(math.ceil(max([padding, dx, dy])))\n",
    "        outputfile = os.path.join(folder_path, object_name, filter)\n",
    "        image_registraion(objfiles, offsets, padding, outputfile)\n",
    "\n",
    "    # Align master object files\n",
    "    objfiles = glob.glob(os.path.join(folder_path, object_name, 'padded_*.fit'))\n",
    "    offsets = []\n",
    "        \n",
    "    for i,objfile in enumerate(objfiles):\n",
    "        filter = fits.getheader(objfile)['FILTER']\n",
    "        if filter=='Visual':\n",
    "            fg = fg_V\n",
    "            bg = bg_V\n",
    "            file = 'master_Visual.fit'\n",
    "        elif filter=='Blue':\n",
    "            fg = fg_B\n",
    "            bg = bg_B\n",
    "            file = 'master_Blue.fit'\n",
    "        else:\n",
    "            fg = fg_R\n",
    "            bg = bg_R\n",
    "            file = 'master_Red.fit'\n",
    "            \n",
    "        (dx, dy) = measure_offset(objfile, objfiles[nref], fg, bg)\n",
    "        offsets.append((dx, dy))\n",
    "        print(f'{objfile} offset by ({dx}, {dy})')\n",
    "        padding = int(math.ceil(max([padding, dx, dy])))\n",
    "            \n",
    "    outputfile = os.path.join(folder_path, object_name)\n",
    "    image_registraion(objfiles, offsets, padding, outputfile)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7276aca4-c47e-4ec8-84ad-ed953b51ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction2(folder_path, object_name):\n",
    "    '''\n",
    "    Performs data reduction on images.\n",
    "\n",
    "    Arguments:\n",
    "        folder_path (string): path to the top level data folder\n",
    "        object_name (string): name of object specific data subfolder\n",
    "\n",
    "    Return:\n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    # Create master bias file\n",
    "    biasfiles = glob.glob(os.path.join(folder_path, 'Calibration', 'Bias', 'CSJ*.fit'))\n",
    "    master_bias_path = os.path.join(folder_path, 'Calibration', 'Bias', 'Master_bias.fit')\n",
    "    m_bias = master_bias(biasfiles, master_bias_path)\n",
    "    \n",
    "    # Create master dark file\n",
    "    darkfiles = glob.glob(os.path.join(folder_path, 'Calibration', 'Dark','CSJ*.fit'))\n",
    "    master_dark_path = os.path.join(folder_path, 'Calibration', 'Dark', 'Master_dark.fit')\n",
    "    m_dark = master_dark(darkfiles, m_bias, master_dark_path) \n",
    "        \n",
    "   # Create master flat file\n",
    "\n",
    "    for filter in ['Red', 'Blue', 'Visual']:\n",
    "        flatfiles = glob.glob(os.path.join(folder_path, 'Calibration', 'Flat', filter ,'PBH*.fit'))\n",
    "        master_flat_path = os.path.join(folder_path, 'Calibration', 'Flat', filter , 'Master_flat.fit')\n",
    "        master_flat(flatfiles, m_bias, m_dark, master_flat_path) \n",
    "\n",
    "    # Reduce object files\n",
    "    for filter in ['Red', 'Blue', 'Visual']:\n",
    "        master_flatfile = os.path.join(folder_path, 'Calibration', 'Flat', filter , 'Master_flat.fit')\n",
    "        objfiles = glob.glob(os.path.join(folder_path, object_name, filter ,'CSJ*.fit'))\n",
    "\n",
    "        for objfile in objfiles:\n",
    "            outputfile = os.path.join(folder_path, object_name, filter)\n",
    "            reduce_image(objfile, m_bias, m_dark, master_flatfile, outputfile)\n",
    "\n",
    "    # Coordinates for Visual, Blue, and Red\n",
    "    fg_V = (922, 3010) \n",
    "    bg_V = (2752, 1594) \n",
    "    fg_B = (733,3064)\n",
    "    bg_B = bg_V\n",
    "    fg_R = (943, 2989)\n",
    "    bg_R = bg_V\n",
    "\n",
    "    # Compute offsets between object images, and shift, pad, and stack them\n",
    "    for filter in ['Red', 'Blue', 'Visual']:\n",
    "        if filter in 'Visual':\n",
    "            fg = fg_V\n",
    "            bg = bg_V\n",
    "        elif filter in 'Blue':\n",
    "            fg = fg_B\n",
    "            bg = bg_B\n",
    "        else:\n",
    "            fg = fg_R\n",
    "            bg = bg_R\n",
    "        nref = 0 # Simple placeholder - Ideally choose img with best signal to noise ratio\n",
    "        objfiles = glob.glob(os.path.join(folder_path, object_name, filter ,'fdb_*.fit'))\n",
    "        offsets = []\n",
    "        padding = 0\n",
    "        for objfile in objfiles:\n",
    "            (dx, dy) = measure_offset(objfile, objfiles[nref], fg, bg)\n",
    "            offsets.append((dx, dy))\n",
    "            print(f'{objfile} offset by ({dx}, {dy})')\n",
    "            padding = int(math.ceil(max([padding, dx, dy])))\n",
    "        outputfile = os.path.join(folder_path, object_name, filter)\n",
    "        image_registraion(objfiles, offsets, padding, outputfile)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63e0f2a8-db2b-457f-baf5-07f5c4766038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Bias file saved as: Master_bias.fit\n",
      "Master dark file saved as: Master_dark.fit\n",
      "Master flat file saved as: Master_flat.fit\n",
      "Master flat file saved as: Master_flat.fit\n",
      "Master flat file saved as: Master_flat.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000036.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000037.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000038.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000039.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000040.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000041.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000042.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000043.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000044.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000001.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000002.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000003.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000004.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000005.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000006.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000007.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000008.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000009.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000010.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000022.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000023.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000024.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000025.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000026.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000027.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000028.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000029.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000030.fit\n",
      "Reduced image saved as: fdb_CSJ.M_52.00000031.fit\n",
      "Final_project/CSJ_10_26_24\\target\\Red\\fdb_CSJ.M_52.00000036.fit offset by (0.0, 0.0)\n",
      "Final_project/CSJ_10_26_24\\target\\Red\\fdb_CSJ.M_52.00000037.fit offset by (-0.7910508175764281, -0.14951355924774656)\n",
      "Final_project/CSJ_10_26_24\\target\\Red\\fdb_CSJ.M_52.00000038.fit offset by (-0.9785554487346264, 1.203654656349265)\n",
      "Final_project/CSJ_10_26_24\\target\\Red\\fdb_CSJ.M_52.00000039.fit offset by (-0.629691875255844, 3.9985752579216634)\n",
      "Final_project/CSJ_10_26_24\\target\\Red\\fdb_CSJ.M_52.00000040.fit offset by (-3.2846861777064547, 1.380160690170685)\n",
      "Final_project/CSJ_10_26_24\\target\\Red\\fdb_CSJ.M_52.00000041.fit offset by (-4.5812849793308175, 2.7894747565417912)\n",
      "Final_project/CSJ_10_26_24\\target\\Red\\fdb_CSJ.M_52.00000042.fit offset by (-5.653022641930752, 4.512656312804953)\n",
      "Final_project/CSJ_10_26_24\\target\\Red\\fdb_CSJ.M_52.00000043.fit offset by (-6.396894382686417, 5.956986149268545)\n",
      "Final_project/CSJ_10_26_24\\target\\Red\\fdb_CSJ.M_52.00000044.fit offset by (-7.1126215623949385, 4.612184833190504)\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000036.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000037.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000038.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000039.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000040.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000041.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000042.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000043.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000044.fit\n",
      "Stacked image saved as: Stacked_image.fit\n",
      "Final_project/CSJ_10_26_24\\target\\Blue\\fdb_CSJ.M_52.00000001.fit offset by (0.0, 0.0)\n",
      "Final_project/CSJ_10_26_24\\target\\Blue\\fdb_CSJ.M_52.00000002.fit offset by (6.060521990622306, -10.392174840040855)\n",
      "Final_project/CSJ_10_26_24\\target\\Blue\\fdb_CSJ.M_52.00000003.fit offset by (5.4728888992806475, 3.565937355459887)\n",
      "Final_project/CSJ_10_26_24\\target\\Blue\\fdb_CSJ.M_52.00000004.fit offset by (3.3230861815579047, 0.49441689629078667)\n",
      "Final_project/CSJ_10_26_24\\target\\Blue\\fdb_CSJ.M_52.00000005.fit offset by (6.004849908691895, 1.619862738780185)\n",
      "Final_project/CSJ_10_26_24\\target\\Blue\\fdb_CSJ.M_52.00000006.fit offset by (1.967324012867575, -8.21570984732109)\n",
      "Final_project/CSJ_10_26_24\\target\\Blue\\fdb_CSJ.M_52.00000007.fit offset by (1.2331636550182914, -11.24378270220879)\n",
      "Final_project/CSJ_10_26_24\\target\\Blue\\fdb_CSJ.M_52.00000008.fit offset by (-5.953788533637475, -5.364105401472628)\n",
      "Final_project/CSJ_10_26_24\\target\\Blue\\fdb_CSJ.M_52.00000009.fit offset by (-6.360578769975376, -6.103036931483501)\n",
      "Final_project/CSJ_10_26_24\\target\\Blue\\fdb_CSJ.M_52.00000010.fit offset by (-4.703712615022905, -7.71611751608906)\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000001.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000002.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000003.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000004.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000005.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000006.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000007.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000008.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000009.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000010.fit\n",
      "Stacked image saved as: Stacked_image.fit\n",
      "Final_project/CSJ_10_26_24\\target\\Visual\\fdb_CSJ.M_52.00000022.fit offset by (0.0, 0.0)\n",
      "Final_project/CSJ_10_26_24\\target\\Visual\\fdb_CSJ.M_52.00000023.fit offset by (-3.6266036251789693, 0.13096983093860248)\n",
      "Final_project/CSJ_10_26_24\\target\\Visual\\fdb_CSJ.M_52.00000024.fit offset by (-3.609377199323337, 0.19502488866586631)\n",
      "Final_project/CSJ_10_26_24\\target\\Visual\\fdb_CSJ.M_52.00000025.fit offset by (-4.967354087595325, 1.0701886125993798)\n",
      "Final_project/CSJ_10_26_24\\target\\Visual\\fdb_CSJ.M_52.00000026.fit offset by (-6.171445344644745, 2.248724973579452)\n",
      "Final_project/CSJ_10_26_24\\target\\Visual\\fdb_CSJ.M_52.00000027.fit offset by (-6.938139382011084, 0.7857948150246712)\n",
      "Final_project/CSJ_10_26_24\\target\\Visual\\fdb_CSJ.M_52.00000028.fit offset by (-5.909076416911425, 4.601724606939646)\n",
      "Final_project/CSJ_10_26_24\\target\\Visual\\fdb_CSJ.M_52.00000029.fit offset by (-6.567359243430872, 2.1990523377431703)\n",
      "Final_project/CSJ_10_26_24\\target\\Visual\\fdb_CSJ.M_52.00000030.fit offset by (-7.64755496291351, 2.7975770556445596)\n",
      "Final_project/CSJ_10_26_24\\target\\Visual\\fdb_CSJ.M_52.00000031.fit offset by (-8.22568009157322, 2.4380205823828627)\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000022.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000023.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000024.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000025.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000026.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000027.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000028.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000029.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000030.fit\n",
      "Shifted image saved as: s_fdb_CSJ.M_52.00000031.fit\n",
      "Stacked image saved as: Stacked_image.fit\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'Final_project/CSJ_10_26_24'\n",
    "object = 'target'\n",
    "reduction2(folder_path, object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74982c04-4a82-46f7-bcb1-7d9585f188c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with std star coordinates\n",
    "def reduction3(folder_path, object_name):\n",
    "    '''\n",
    "    Performs data reduction on images.\n",
    "\n",
    "    Arguments:\n",
    "        folder_path (string): path to the top level data folder\n",
    "        object_name (string): name of object specific data subfolder\n",
    "\n",
    "    Return:\n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    # Create master bias file\n",
    "    biasfiles = glob.glob(os.path.join(folder_path, 'Calibration', 'Bias', 'CSJ*.fit'))\n",
    "    master_bias_path = os.path.join(folder_path, 'Calibration', 'Bias', 'Master_bias.fit')\n",
    "    m_bias = master_bias(biasfiles, master_bias_path)\n",
    "    \n",
    "    # Create master dark file\n",
    "    darkfiles = glob.glob(os.path.join(folder_path, 'Calibration', 'Dark','CSJ*.fit'))\n",
    "    master_dark_path = os.path.join(folder_path, 'Calibration', 'Dark', 'Master_dark.fit')\n",
    "    m_dark = master_dark(darkfiles, m_bias, master_dark_path) \n",
    "        \n",
    "   # Create master flat file\n",
    "\n",
    "    for filter in ['Red', 'Blue', 'Visual']:\n",
    "        flatfiles = glob.glob(os.path.join(folder_path, 'Calibration', 'Flat', filter ,'PBH*.fit'))\n",
    "        master_flat_path = os.path.join(folder_path, 'Calibration', 'Flat', filter , 'Master_flat.fit')\n",
    "        master_flat(flatfiles, m_bias, m_dark, master_flat_path) \n",
    "\n",
    "    # Reduce object files\n",
    "    for filter in ['Red', 'Blue', 'Visual']:\n",
    "        master_flatfile = os.path.join(folder_path, 'Calibration', 'Flat', filter , 'Master_flat.fit')\n",
    "        objfiles = glob.glob(os.path.join(folder_path, object_name, filter ,'CSJ*.fit'))\n",
    "\n",
    "        for objfile in objfiles:\n",
    "            outputfile = os.path.join(folder_path, object_name, filter)\n",
    "            reduce_image(objfile, m_bias, m_dark, master_flatfile, outputfile)\n",
    "\n",
    "    # Coordinates for Visual, Blue, and Red\n",
    "    fg_V = (1731, 1584) \n",
    "    bg_V = (2100, 2300) \n",
    "    fg_B = (1774, 1490)\n",
    "    bg_B = bg_V\n",
    "    fg_R = (1756,1524)\n",
    "    bg_R = bg_V\n",
    "\n",
    "    # Compute offsets between object images, and shift, pad, and stack them\n",
    "    for filter in ['Red', 'Blue', 'Visual']:\n",
    "        if filter in 'Visual':\n",
    "            fg = fg_V\n",
    "            bg = bg_V\n",
    "        elif filter in 'Blue':\n",
    "            fg = fg_B\n",
    "            bg = bg_B\n",
    "        else:\n",
    "            fg = fg_R\n",
    "            bg = bg_R\n",
    "        nref = 0 # Simple placeholder - Ideally choose img with best signal to noise ratio\n",
    "        objfiles = glob.glob(os.path.join(folder_path, object_name, filter ,'fdb_*.fit'))\n",
    "        offsets = []\n",
    "        padding = 0\n",
    "        for objfile in objfiles:\n",
    "            (dy, dx) = measure_offset(objfile, objfiles[nref], fg, bg)\n",
    "            offsets.append((dy, dx))\n",
    "            print(f'{objfile} offset by ({dx}, {dy})')\n",
    "            padding = int(math.ceil(max([padding, dx, dy])))\n",
    "        outputfile = os.path.join(folder_path, object_name, filter)\n",
    "        image_registraion(objfiles, offsets, padding, outputfile)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36107e33-4428-4920-8f20-57e519293cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'Final_project/CSJ_10_26_24'\n",
    "object = 'standard'\n",
    "reduction2(folder_path, object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b9aa30-1e3f-4c4f-8635-1720c8093636",
   "metadata": {},
   "source": [
    "### The following calculations are to align the stacked images of the cluster of all 3 bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a5d5f82-6d25-4293-a221-fdd5ec684b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(4108, 4108)\n",
      "(4110, 4110)\n",
      "Written Red\n",
      "0\n",
      "(4110, 4110)\n",
      "(4110, 4110)\n",
      "Written Blue\n",
      "4\n",
      "(4106, 4106)\n",
      "(4110, 4110)\n",
      "Written Visual\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'Final_project/CSJ_10_26_24'\n",
    "object = 'target'\n",
    "\n",
    "images = []\n",
    "images.append(os.path.join(folder_path, object, 'Red/Red_Stacked_image.fit'))\n",
    "images.append(os.path.join(folder_path, object, 'Blue/Blue_Stacked_image.fit'))\n",
    "images.append(os.path.join(folder_path, object, 'Visual/Visual_Stacked_image.fit'))\n",
    "\n",
    "stacked_files = []\n",
    "sizes = []\n",
    "hdr = []\n",
    "\n",
    "for i,img in enumerate(images):\n",
    "    hdr.append(fits.getheader(images[i]))\n",
    "    stacked_files.append(fits.getdata(img))\n",
    "    sizes.append(stacked_files[i].shape[0])\n",
    "\n",
    "for i in range(3):\n",
    "    print(np.max(sizes)-sizes[i])\n",
    "    print(stacked_files[i].shape)\n",
    "    padded_img = np.pad(stacked_files[i], (int)((np.max(sizes)-sizes[i])/2), 'constant', constant_values = -1)\n",
    "    print(padded_img.shape)\n",
    "    filter = hdr[i]['FILTER']\n",
    "    outputfile_name = os.path.join(folder_path, object,'padded_'+filter+'_stacked_image.fit')\n",
    "    fits.writeto(outputfile_name, padded_img, header=hdr[i], output_verify='exception', overwrite=True, checksum=False)\n",
    "    print(f'Written {filter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98ba75ea-509f-4bdd-b821-86a9e593f323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0),\n",
       " (-30.046506749679104, 43.53576151359041),\n",
       " (-10.637280934582648, 21.493560641789834)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_V = (901, 3016) \n",
    "bg_V = (2752, 1594) \n",
    "\n",
    "files = glob.glob('Final_project/CSJ_10_26_24/target/padded*.fit')\n",
    "offsets = []\n",
    "for img in files:\n",
    "    offsets.append(measure_offset(img, files[0], fg_V, bg_V))\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e3660ea-eaff-41d9-b563-27c0459eabd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Final_project/CSJ_10_26_24/target\\\\padded_Blue_stacked_image.fit',\n",
       " 'Final_project/CSJ_10_26_24/target\\\\padded_Red_stacked_image.fit',\n",
       " 'Final_project/CSJ_10_26_24/target\\\\padded_Visual_stacked_image.fit']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb320480-ccd7-40e2-a442-fefdb3cbd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = [(0,0),(40,-62),(11,-29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e40aeacc-5bfc-4110-a75e-b96e9b095bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifted image saved as: s_padded_Blue_stacked_image.fit\n",
      "Shifted image saved as: s_padded_Red_stacked_image.fit\n",
      "Shifted image saved as: s_padded_Visual_stacked_image.fit\n"
     ]
    }
   ],
   "source": [
    "for ii in range(3):\n",
    "    file = files[ii]\n",
    "    offset = offsets[ii]\n",
    "    img = fits.getdata(file)\n",
    "    hdr = fits.getheader(file)\n",
    "    img[np.isnan(img)] = 0.0\n",
    "    img[np.isinf(img)] = 0.0\n",
    "    \n",
    "    shifted_img = shift(img, offset, cval = -1)\n",
    "    shifted_img[np.isnan(shifted_img)] = 0.0\n",
    "    shifted_img[np.isinf(shifted_img)] = 0.0\n",
    "    outputfile_name = os.path.join('Final_project/CSJ_10_26_24/target' , 's_' + os.path.basename(file))\n",
    "    #print('writing shifted image', os.path.basename(outputfile))\n",
    "    fits.writeto(outputfile_name, shifted_img, header=hdr, output_verify='exception', overwrite=True, checksum=False)\n",
    "    print(f\"Shifted image saved as: {os.path.basename(outputfile_name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1a8e2-a6c0-4e97-947c-6b3dd311fad4",
   "metadata": {},
   "source": [
    "### The following calculations are to align the stacked images of the std star of all 3 bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48da265-e89d-4379-a5ee-fabc9f2a5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'Final_project/CSJ_10_26_24'\n",
    "object = 'standard'\n",
    "\n",
    "images = []\n",
    "images.append(os.path.join(folder_path, object, 'Red/Stacked_image.fit'))\n",
    "images.append(os.path.join(folder_path, object, 'Blue/Stacked_image.fit'))\n",
    "images.append(os.path.join(folder_path, object, 'Visual/Stacked_image.fit'))\n",
    "\n",
    "stacked_files = []\n",
    "sizes = []\n",
    "hdr = []\n",
    "\n",
    "for i,img in enumerate(images):\n",
    "    hdr.append(fits.getheader(images[i]))\n",
    "    stacked_files.append(fits.getdata(img))\n",
    "    sizes.append(stacked_files[i].shape[0])\n",
    "\n",
    "for i in range(3):\n",
    "    print(np.max(sizes)-sizes[i])\n",
    "    print(stacked_files[i].shape)\n",
    "    padded_img = np.pad(stacked_files[i], (int)((np.max(sizes)-sizes[i])/2), 'constant', constant_values = -1)\n",
    "    print(padded_img.shape)\n",
    "    filter = hdr[i]['FILTER']\n",
    "    outputfile_name = os.path.join(folder_path, object,'padded_'+filter+'_stacked_image.fit')\n",
    "    fits.writeto(outputfile_name, padded_img, header=hdr[i], output_verify='exception', overwrite=True, checksum=False)\n",
    "    print(f'Written {filter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d20335-4bc8-47cf-8acc-6bcd4676c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_V = (1731, 1584) \n",
    "bg_V = (2100, 2300)\n",
    "\n",
    "files = glob.glob('Final_project/CSJ_10_26_24/standard/padded*.fit')\n",
    "offsets = []\n",
    "for img in files:\n",
    "    offsets.append(measure_offset(img, files[0], fg_V, bg_V))\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7788cd-b9bc-4291-a0bc-e7d89f26f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37299728-8a3a-489d-936c-992cd39138f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = [(60, -34), (34,-8), (0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05165a-e8ad-4b9f-9728-9535f76d350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(3):\n",
    "    file = files[ii]\n",
    "    offset = offsets[ii]\n",
    "    img = fits.getdata(file)\n",
    "    hdr = fits.getheader(file)\n",
    "    img[np.isnan(img)] = 0.0\n",
    "    img[np.isinf(img)] = 0.0\n",
    "    \n",
    "    shifted_img = shift(img, offset, cval = -1)\n",
    "    shifted_img[np.isnan(shifted_img)] = 0.0\n",
    "    shifted_img[np.isinf(shifted_img)] = 0.0\n",
    "    outputfile_name = os.path.join('Final_project/CSJ_10_26_24/standard' , 's_' + os.path.basename(file))\n",
    "    #print('writing shifted image', os.path.basename(outputfile))\n",
    "    fits.writeto(outputfile_name, shifted_img, header=hdr, output_verify='exception', overwrite=True, checksum=False)\n",
    "    print(f\"Shifted image saved as: {os.path.basename(outputfile_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a02702-1725-4711-80f6-5ce55dcf74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_stacked_images(images):\n",
    "    '''Aligns stacked images of all three filters and writes the shifted file\n",
    "    Parameters:\n",
    "    images (list of strings): list of the stacked images to be aligned\n",
    "    return: none\n",
    "    '''\n",
    "    \n",
    "    stacked_files = []\n",
    "    sizes = []\n",
    "    hdr = []\n",
    "    \n",
    "    for i,img in enumerate(images):\n",
    "        hdr.append(fits.getheader(images[i]))\n",
    "        stacked_files.append(fits.getdata(img))\n",
    "        sizes.append(stacked_files[i].shape[0])\n",
    "    \n",
    "    for i in range(3):\n",
    "        padded_img = np.pad(stacked_files[i], (int)((np.max(sizes)-sizes[i])/2), 'constant', constant_values = -1)\n",
    "        filter = hdr[i]['FILTER']\n",
    "        outputfile_name = os.path.join(folder_path, object,'padded_'+filter+'_stacked_image.fit')\n",
    "        fits.writeto(outputfile_name, padded_img, header=hdr[i], output_verify='exception', overwrite=True, checksum=False)\n",
    "\n",
    "    # for the cluster\n",
    "    fg_V = (922, 3010) \n",
    "    bg_V = (2752, 1594) \n",
    "    \n",
    "    # for std star\n",
    "    fg_V = (1731, 1584) \n",
    "    bg_V = (2100, 2300)\n",
    "    \n",
    "    files = glob.glob(os.path.join(folder, object, 'padded*.fit'))\n",
    "    offsets = []\n",
    "    for img in files:\n",
    "        offsets.append(measure_offset(img, files[0], fg_V, bg_V))\n",
    "\n",
    "    for ii in range(3):\n",
    "        file = files[ii]\n",
    "        offset = offsets[ii]\n",
    "        img = fits.getdata(file)\n",
    "        hdr = fits.getheader(file)\n",
    "        img[np.isnan(img)] = 0.0\n",
    "        img[np.isinf(img)] = 0.0\n",
    "        \n",
    "        shifted_img = shift(img, offset, cval = -1)\n",
    "        shifted_img[np.isnan(shifted_img)] = 0.0\n",
    "        shifted_img[np.isinf(shifted_img)] = 0.0\n",
    "        outputfile_name = os.path.join(folder, object, 's_' + os.path.basename(file))\n",
    "        fits.writeto(outputfile_name, shifted_img, header=hdr, output_verify='exception', overwrite=True, checksum=False)\n",
    "        print(f\"Shifted image saved as: {os.path.basename(outputfile_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1abe2390-7024-4cc2-81d5-eceb8009d598",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = {\n",
    " \"target\" : \n",
    "    {\"Visual\":{\"fg\":(922, 3010), \"bg\":(2752, 1594)},\n",
    "    \"Blue\": {\"fg\":(733,3064), \"bg\":(2752, 1594)},\n",
    "    \"Red\": {\"fg\":(943, 2989), \"bg\":(2752, 1594)}\n",
    "    },\n",
    " \"standard\":\n",
    "    {\"Visual\":{\"fg\":(1731, 1584), \"bg\":(2100, 2300)},\n",
    "    \"Blue\": {\"fg\":(1774, 1490), \"bg\":(2100, 2300)},\n",
    "    \"Red\": {\"fg\":(1756,1524), \"bg\":(2100, 2300)}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64944993-01d7-463a-b46a-8d90ebf287a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(922, 3010)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object = 'target'\n",
    "filter = 'Visual'\n",
    "coordinates[object][filter]['fg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d57ec0c-7a5a-412e-9732-f706213df43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18f58b8-111c-4c46-98d3-197f1aae7e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b172e-a10f-41d0-a201-a34f0f580570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
